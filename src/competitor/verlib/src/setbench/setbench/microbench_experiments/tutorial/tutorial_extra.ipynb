{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using JupyterNB to explore collected data\n",
    "\n",
    "This Jupyter Notebook works through a series of examples to show how you can explore, display and analyze data collected by `run_experiment.py` (and stored in `output_database.sqlite`).\n",
    "\n",
    "It is **strongly** recommended that you view this notebook in VSCode.\n",
    "\n",
    "## Generating some data to analyze\n",
    "\n",
    "To *produce* data that you can analyze here, you should:\n",
    "\n",
    "1. execute `run_experiment.py` from the command line (with suitable arguments).\n",
    "2. copy the resulting `data` folder into this directory.\n",
    "\n",
    "Note that you can learn about the arguments to `run_experiment.py` by running:\n",
    "\n",
    "`./run_experiment.py -h`\n",
    "\n",
    "To generate a small amount of data to analyze (should take one or two minutes), try running the following *in directory* `../example`:\n",
    "\n",
    "`./run_testing.sh`\n",
    "\n",
    "Note that this runs a set of experiments defined by `_user_experiments.py` in `testing` mode. In `testing` mode, only a subset of the experimental trials are run, and each trial run is for a greatly reduced time. Thus, the results are essentially meaningless, but they can be generated quickly. (This `testing` mode is primarily included to allow you to quickly run through many different experiments and check that they don't experience immediate crashes, or incomplete output.)\n",
    "\n",
    "(You can `cat run_testing.sh` to see how it does this. It's quite simple...)\n",
    "\n",
    "To run a more comprehensive test (which should take an hour or less):\n",
    "\n",
    "`./run_production.sh`\n",
    "\n",
    "## Alternatively, you can run the following code (3-5 min):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def define_experiment(exp_dict, args):\n",
    "    set_dir_compile  (exp_dict, os.getcwd() + '/../../microbench')\n",
    "    set_dir_tools    (exp_dict, os.getcwd() + '/../../tools')\n",
    "    set_dir_run      (exp_dict, os.getcwd() + '/bin')\n",
    "\n",
    "    add_run_param    (exp_dict, 'INS_DEL_FRAC'    , ['0.0 0.0', '0.5 0.5', '20.0 10.0'])\n",
    "    add_run_param    (exp_dict, 'MAXKEY'          , [2000000, 20000000])\n",
    "    add_run_param    (exp_dict, 'DS_TYPENAME'     , ['brown_ext_ist_lf', 'brown_ext_abtree_lf', 'bronson_pext_bst_occ'])\n",
    "    add_run_param    (exp_dict, 'thread_pinning'  , ['-pin ' + shell_to_str('cd ' + get_dir_tools(exp_dict) + ' ; ./get_pinning_cluster.sh', exit_on_error=True)])\n",
    "    add_run_param    (exp_dict, '__trials'        , [1])\n",
    "    add_run_param    (exp_dict, 'TOTAL_THREADS'   , [1] + shell_to_listi('cd ' + get_dir_tools(exp_dict) + ' ; ./get_thread_counts_numa_nodes.sh', exit_on_error=True))\n",
    "\n",
    "    set_cmd_compile  (exp_dict, 'make -j8 bin_dir={__dir_run}')\n",
    "    set_cmd_run      (exp_dict, 'LD_PRELOAD=../../../lib/libjemalloc.so timeout 300 numactl --interleave=all time ./{DS_TYPENAME}.debra -nwork {TOTAL_THREADS} -insdel {INS_DEL_FRAC} -k {MAXKEY} -t 500 {thread_pinning} -rq 0 -rqsize 1 -nrq 0')\n",
    "\n",
    "    add_data_field   (exp_dict, 'total_throughput'  , coltype='INTEGER', validator=is_positive)\n",
    "    add_data_field   (exp_dict, 'PAPI_L3_TCM'       , coltype='REAL')\n",
    "    add_data_field   (exp_dict, 'PAPI_L2_TCM'       , coltype='REAL')\n",
    "    add_data_field   (exp_dict, 'PAPI_TOT_CYC'      , coltype='REAL')\n",
    "    add_data_field   (exp_dict, 'PAPI_TOT_INS'      , coltype='REAL')\n",
    "    add_data_field   (exp_dict, 'maxresident_mb'    , coltype='REAL', extractor=get_maxres)\n",
    "    add_data_field   (exp_dict, 'tree_stats_height' , coltype='INTEGER')\n",
    "    add_data_field   (exp_dict, 'validate_result'   , validator=is_equal('success'))\n",
    "    add_data_field   (exp_dict, 'MILLIS_TO_RUN'     , validator=is_positive)\n",
    "    add_data_field   (exp_dict, 'RECLAIM')\n",
    "    add_data_field   (exp_dict, 'POOL')\n",
    "\n",
    "def get_maxres(exp_dict, file_name, field_name):\n",
    "    ## manually parse the maximum resident size from the output of `time` and add it to the data file\n",
    "    maxres_kb_str = shell_to_str('grep \"maxres\" {} | cut -d\" \" -f6 | cut -d\"m\" -f1'.format(file_name))\n",
    "    return float(maxres_kb_str) / 1000\n",
    "\n",
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "enable_tee_stdout()\n",
    "run_in_jupyter(define_experiment, cmdline_args='--testing -crd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data into this notebook\n",
    "\n",
    "Once you have run one of the commands above to generate data, we can load it into this notebook to work with it. We start by appending the path `../../tools/data_framework` to the system PATH variable, so that `python` can find `run_experiment.py`. This file contains many functions for analyzing data and producing plots.\n",
    "\n",
    "We then run `init_for_jupyter('_user_experiment.py')` which actually **runs** `run_experiment.py` with specific arguments that cause it to simply **load** the existing sqlite database (without running any experiments, or modifying any stored data).\n",
    "\n",
    "If you are running VSCode and want to see how `init_for_jupyter` works, you can hold CTRL (or CMD on OSX) and click the function name in the code below.\n",
    "\n",
    "While we're at it, we can set the style for plots in this notebook to use a dark theme.\n",
    "\n",
    "*Note that you must run the following initialization code cell before any cells below it will work...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "init_for_jupyter('../example/_user_experiment.py')\n",
    "plt.style.use('dark_background')\n",
    "print(\"Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing available data columns\n",
    "\n",
    "Next let's list the available data columns. We use a function `select_to_dataframe()` provided in `run_experiment.py` to query the sqlite database to fetch the names of columns, along with the IPython `display()` function to pretty print the output in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## the following query will select ZERO rows because of the WHERE clause.\n",
    "## however, it will still fetch all columns.\n",
    "df = select_to_dataframe('select * from data where 1==0') \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## we can also retrieve the columns as a list and print as plain text\n",
    "df = select_to_dataframe('select * from data where 1==0') \n",
    "col_list = df.columns.values\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run_experiment.py also provides a convenience function for this:\n",
    "print(get_headers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the DATA table\n",
    "\n",
    "Let's try to query some columns from the DATA table. We will again use `select_to_dataframe`. We will also demonstrate the use of the WHERE clause to filter data. (If you need to brush up on your SQL, you might check out the sqlite documentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = select_to_dataframe('select DS_TYPENAME, TOTAL_THREADS, total_throughput from DATA where MAXKEY == 2000000 and INS_DEL_FRAC == \"0.5 0.5\"')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_to_dataframe('select * from data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing `bar charts` *inline* in a data frame\n",
    "\n",
    "`Pandas` `DataFrame` offers a very cool `style.bar` function, which lets you turn your columns into a sort of simple `bar chart`. For example, we can create bar charts out of `total_throughput` and 'PAPI_TOT_CYC'.\n",
    "\n",
    "This feature can make it *much* easier to visually parse numeric table data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('select * from data where MAXKEY==2000000 and INS_DEL_FRAC==\"0.5 0.5\" order by DS_TYPENAME, TOTAL_THREADS')\n",
    "df.style.bar(subset=['total_throughput', 'PAPI_TOT_CYC'], color='#5fba7d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "\n",
    "We can also easily create a *plot* from this data, by calling the `plot_to_axes` function provided by the data framework in `_jupyter_libs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_axes(series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to provide a python dictionary containing field / value pairs instead of an explicit where clause, then use `plot_to_axes_dict`, and we will construct the WHERE clause for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_to_axes_dict(series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', filter_values=dict({'MAXKEY': 2000000, 'INS_DEL_FRAC': '0.5 0.5'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to **also** display the **data** being plotted, you can specify argument `display_data=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_axes(series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick sanity check\n",
    "\n",
    "The ability to quickly display data for a plot is especially useful when you want to take a quick glance at one slice of your data as a sanity check to ensure that, for example, you aren't taking an inappropriate average over rows which differ in an important column you've forgotten to query.\n",
    "\n",
    "You might spot such a scenario by observing that the number of rows being aggregated looks wrong, or by noticing that very different looking values are being averaged.\n",
    "\n",
    "For example, consider the following bar plot, where we're inappropriately averaging `total_throughput` values over rows that differ in the `DS_TYPENAME` column, but we've failed to notice this, because we simply haven't included `DS_TYPENAME` in our query.\n",
    "\n",
    "It's not too hard to see that we're averaging several `total_throughput`s that look quite different from one another, as we group by `TOTAL_THREADS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_axes(x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us determine *which field we're missing* from our query, we can change our argument to `display_data='full'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_axes(x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, to make it even easier to tell which field we've neglected, you can change the argument to `display_data='diff'`. This only displays columns that:\n",
    "- are not prefixed with '__'\n",
    "  (as those are added by `run_experiment.py` rather than the user)\n",
    "- do not contain identical data in all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_axes(x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data='diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can filter the returned data more aggressively\n",
    "Just specify `display_data='diff2'`. In addition to the filtering in `'diff'` mode, this displays only the *subset* of columns in `'diff'` that were specified by the user via `add_run_param()` in `_user_experiment.py`, and also only displays fields that we haven't included in our plot. That is, we only display columns that:\n",
    "\n",
    "- are not already in our plot\n",
    "- were explicitly added as a varying experimental parameter using `add_run_param()`\n",
    "- are not prefixed with '__'\n",
    "- do not contain identical data in all rows\n",
    "\n",
    "As we can see in the example below, `display_data='diff2'` immediately highlights the column we forgot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_to_axes(x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data='diff2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add `DS_TYPENAME` to the plot as our `series` field, and rerun with `display_data='diff2'`, we can see that the filtered `diff2` data frame is completely empty!\n",
    "\n",
    "This is the expected result when using `diff2` and aggregating row values appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_to_axes(series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"', display_data='diff2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually placing multiple plots in a grid\n",
    "\n",
    "The function `plot_to_axes` takes a matplotlib/pandas/seaborn `axes` object as an optional argument called `ax`. This allows us to easily render plots in columns/rows of a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a 2x2 grid of plots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(12, 6))\n",
    "## fill in the bottom left grid cell\n",
    "plot_to_axes(ax=axes[1,0], series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.5 0.5\"')\n",
    "## fill in the bottom right grid cell\n",
    "plot_to_axes(ax=axes[1,1], series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE MAXKEY == 2000000 AND INS_DEL_FRAC == \"0.0 0.0\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically producing plots to fill a grid\n",
    "\n",
    "Tools like the `Seaborn` library's `factorplot` make it easy to plot **5-dimensional data** as *rows* and *columns* of plots, each containing *series*, *x* and *y* dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "g = sns.factorplot(kind='bar', data=df, col='INS_DEL_FRAC', row='MAXKEY', hue='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', margin_titles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FacetGrid for more control\n",
    "\n",
    "You can produce the same sort of plot using Seaborn's `FacetGrid` function. `FacetGrid` creates a grid of plots backed by a dataframe.\n",
    "\n",
    "You specify `col` and `row` fields, and it will filter the appropriately for each cell in the grid, and make it available to you.\n",
    "\n",
    "However, unlike `factorplot`, `FacetGrid` does not plot the data for you. Instead, you have to use the `map` function to specify how the data in each grid cell should be plotted. This gives you more control over the end result. (For example, although we don't demonstrate this here, you could use different plot styles in different grid cells.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(sns.barplot, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing a FacetGrid: changing the legend and resizing the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(sns.barplot, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "\n",
    "## five-column legend at the bottom\n",
    "g.add_legend(loc='lower center', ncol=5)\n",
    "## shift the bottom of the plots upwards (by 14% of the figure)\n",
    "## to avoid text axis title text overlapping the legend\n",
    "g.fig.subplots_adjust(bottom=0.14, top=1, left=0, right=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the bottom legend leaves us with less vertical space to see our plots. We can set our figure size manually to correct the size/shape as we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(sns.barplot, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "\n",
    "g.add_legend(loc='lower center', ncol=5)\n",
    "g.fig.subplots_adjust(bottom=0.14, top=1, left=0, right=1)\n",
    "\n",
    "## set the figure to a desired size\n",
    "g.fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heavily customizing the style of a FacetGrid\n",
    "\n",
    "Here, we define a style for each series, by constructing explicit maps from series values to marker types, colors, line dashing styles, and line sizes. This way, we can ensure a **consistent** mapping from individual series values to style (line/marker/color/size). \n",
    "\n",
    "Once we have dictionaries mapping series values to each of these style parameters, we can feed them carefully to `sns.lineplot()` by running the `FacetGrid` `map()` function on our own intermediate function called `plot_facet()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "\n",
    "## define lists of values that will consume for each series,\n",
    "## wrapping around to the beginning of each list if we run out of elements.\n",
    "markers = [ '^', 'o', 's', '+', 'x', 'v', '*', 'X', '|', '.', 'd' ]\n",
    "palette = [ 'red', 'blue', 'yellow', 'green' ]\n",
    "dashes = [ '' ]\n",
    "sizes = [ 1 ]\n",
    "\n",
    "## construct mappings from each series value to round-robin choices from the above\n",
    "plot_style_kwargs = dict(markers=dict(), palette=dict(), sizes=dict(), dashes=dict())\n",
    "distinct_series = select_distinct_field('DS_TYPENAME')\n",
    "for i, series in zip(range(len(distinct_series)), distinct_series):\n",
    "    plot_style_kwargs['markers'][series] = markers[i % len(markers)]\n",
    "    plot_style_kwargs['palette'][series] = palette[i % len(palette)]\n",
    "    plot_style_kwargs['sizes'][series] = sizes[i % len(sizes)]\n",
    "    plot_style_kwargs['dashes'][series] = dashes[i % len(dashes)]\n",
    "\n",
    "## feed those mappings into seaborn lineplot via our own plot_facet function\n",
    "def plot_facet(x, y, series, **kwargs):\n",
    "    sns.lineplot(x=x, y=y, hue=series, style=series, **plot_style_kwargs, **kwargs)\n",
    "\n",
    "## pair our own plot_facet function with map()\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(plot_facet, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "\n",
    "## customize legend and overall figure size\n",
    "g.add_legend(loc='lower center', ncol=5)\n",
    "g.fig.subplots_adjust(bottom=0.14, top=1, left=0, right=1)\n",
    "g.fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making this simpler...\n",
    "\n",
    "Of course a lot of the complexity in the above code cell can be wrapped up in helper functions. For example, we encapsulate the setup for plot markers, dashes, palette and sizes in the `_jupyter_libs` function `get_seaborn_series_styles()`.\n",
    "\n",
    "Note that argument `series` can either be a list of series values, or the name of the series column in the sqlite database's `DATA` table. If it is a column name, then `get_seaborn_series_styles()` will query all distinct values from that column to derive the series values. Otherwise, if it is a list, then styles will be assigned to its elements **in the order they appear in the list**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "\n",
    "style_kwargs = get_seaborn_series_styles('DS_TYPENAME', markers=['^', 'o', 's', '+', 'x', 'v', '*', 'X', '|', '.', 'd'], palette=['red', 'blue', 'yellow', 'green'], dashes=[''], sizes=[1])\n",
    "def plot_facet(x, y, series, **kwargs): ## feed our series styles into sns.lineplot\n",
    "    sns.lineplot(x=x, y=y, hue=series, style=series, **style_kwargs, **kwargs)\n",
    "\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(plot_facet, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "\n",
    "g.add_legend(loc='lower center', ncol=5)\n",
    "g.fig.subplots_adjust(bottom=0.14, top=1, left=0, right=1)\n",
    "g.fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note: if all you want is a **consistent** mapping from series values to a style (rather than a **particular** choice of markers, etc.), then you should know that `get_seaborn_series_styles()` has fairly sane *default* values for markers, palette, dashes and sizes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "\n",
    "style_kwargs = get_seaborn_series_styles('DS_TYPENAME')\n",
    "def plot_facet(x, y, series, **kwargs): ## feed our series styles into sns.lineplot\n",
    "    sns.lineplot(x=x, y=y, hue=series, style=series, **style_kwargs, **kwargs)\n",
    "\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "g.map(plot_facet, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "g.add_legend(loc='lower center', ncol=5)\n",
    "g.fig.subplots_adjust(bottom=0.14, top=1, left=0, right=1)\n",
    "g.fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further simplify by encapsulating the `add_legend`, `subplots_adjust` and `set_size_inches` functions in a `add_legend_and_reshape()` function. This new function takes optional arguments `loc`, `ncol`, `bottom` and `size` (with sane **default values** taken from the code cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_to_dataframe('SELECT MAXKEY, INS_DEL_FRAC, DS_TYPENAME, TOTAL_THREADS, total_throughput FROM DATA')\n",
    "g = sns.FacetGrid(data=df, col='INS_DEL_FRAC', row='MAXKEY', margin_titles=True)\n",
    "style_kwargs = get_seaborn_series_styles('DS_TYPENAME')\n",
    "def plot_facet(x, y, series, **kwargs):\n",
    "    sns.lineplot(x=x, y=y, hue=series, style=series, **style_kwargs, **kwargs)\n",
    "g.map(plot_facet, 'TOTAL_THREADS', 'total_throughput', 'DS_TYPENAME')\n",
    "add_legend_and_reshape(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it all with a single function: `plot_rc`\n",
    "\n",
    "In fact, we think you might want to generate this kind of figure (as a fast way of exploring five dimensions of data) often enough that this entire code cell should be a function:\n",
    "\n",
    "`plot_rc(row, col, series, x, y)`\n",
    "\n",
    "with OPTIONAL arguments:\n",
    "- `where` (default value `''`)\n",
    "- `series_styles` (default value `get_seaborn_series_styles(series)`)\n",
    "- `plot_func` (default value `sns.lineplot`)\n",
    "- `facetgrid_kwargs` (default value dict())\n",
    "- `data` (default value None -- see several code blocks below for usage)\n",
    "\n",
    "The `where` argument (if used) should be a complete sqlite WHERE clause (including the word 'WHERE'). The purpose is to allow you to filter your dataset to ensure that you're aggregating (averaging) values in a sensible way, over a set of rows that it actually makes sense to aggregate.\n",
    "\n",
    "It should be possible to use most `Seaborn` plot functions as the `plot_func` argument.\n",
    "\n",
    "The `facetgrid_kwargs` argument allows you to provide any keyword arguments to the `sns.FacetGrid()` call. (I.e., we will call `sns.FacetGrid(..., **facetgrid_kwargs))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput')\n",
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='PAPI_TOT_CYC')\n",
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='PAPI_TOT_INS')\n",
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='PAPI_L3_TCM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `where` argument to filter before plotting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', where='WHERE DS_TYPENAME != \"brown_ext_ist_lf\" AND MAXKEY <= 10000000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce other types of plots using the same function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rc(row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='maxresident_mb', where='WHERE DS_TYPENAME != \"brown_ext_ist_lf\"', plot_func=sns.barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing a DataFrame to `plot_rc`\n",
    "\n",
    "You can provide a `pandas` `DataFrame` via an optional `data` argument. If you do this, `plot_rc` will use this data instead of querying the `sqlite` database to obtain all of its data.\n",
    "\n",
    "(It may still query the database to get all unique values in the series column, but it will only do this to ensure that series are styled consistently, regardless of *which* series are present in the queried data.)\n",
    "\n",
    "**Why would you want to do this?** Well, as an example, we might want to plot a computed column, such as the average of the `maxresident_mb` column MINUS the minimum value of the same column. \n",
    "\n",
    "To do this, you can compute a suitable column using `sqlite` (likely via a subquery), give it a name, and reference it in the arguments to `plot_rc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = 'DS_TYPENAME != \"brown_ext_ist_lf\"'\n",
    "df = select_to_dataframe('''\n",
    "    select\n",
    "        MAXKEY\n",
    "      , INS_DEL_FRAC\n",
    "      , DS_TYPENAME\n",
    "      , TOTAL_THREADS\n",
    "      , (maxresident_mb - (select min(maxresident_mb) from DATA where {}))\n",
    "        as maxresident_mb_over_minimum\n",
    "    from DATA\n",
    "    where {}\n",
    "'''.format(where, where))\n",
    "\n",
    "plot_rc(data=df, row='MAXKEY', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='maxresident_mb_over_minimum', plot_func=sns.barplot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if, to compute your custom column(s), you need to perform subqueries on data that is **already filtered** to the particular **grid facet** being rendered, then you will have to query for any relevant data *inside* a **custom function** called by `map()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating two columns to form a single series field\n",
    "\n",
    "(This is done via a more complex SQL query string internally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys ; sys.path.append('../../tools/data_framework') ; from run_experiment import *\n",
    "init_for_jupyter('_user_experiment.py')\n",
    "\n",
    "get_dataframe_and_call(\n",
    "      plot_df_line\n",
    "    , series=['DS_TYPENAME', 'RECLAIM']\n",
    "    , x='TOTAL_THREADS'\n",
    "    , y='total_throughput'\n",
    "    , where='where MAXKEY == 2000000 and INS_DEL_FRAC == \"0.5 0.5\"'\n",
    "    , all_possible_series=select_distinct_field(['DS_TYPENAME', 'RECLAIM'])\n",
    "    , legend_call_kwargs=dict(ncol=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line plot with error regions\n",
    "\n",
    "note: error regions are ACTUALLY showing a FAILURE to filter appropriately (we are aggregating over SIX rows for each data point, covering TWO DIFFERENT MAXKEY VALUES). to fix this, try settings \"row='MAXKEY'\" instead of RECLAIM.\n",
    "\n",
    "error regions are showing MIN/MAX value ranges for each data point, because we have set \"ci=100\". by default, that parameter is \"ci=95\". it can also be set to \"sd\" for standard deviation, or disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../../tools/data_framework'); from run_experiment import *\n",
    "init_for_jupyter('_user_experiment.py') ; plt.style.use('dark_background') ## initialize\n",
    "\n",
    "df = select_to_dataframe('select * from data')\n",
    "plot_rc(data=df, row='RECLAIM', col='INS_DEL_FRAC', series='DS_TYPENAME', x='TOTAL_THREADS', y='total_throughput', plot_func=sns.lineplot, facetgrid_kwargs=dict(sharey=False), plot_kwargs=dict(ci=100))\n",
    "\n",
    "#df = select_to_dataframe('select * from data where DS_TYPENAME=\"brown_ext_ist_lf\" and INS_DEL_FRAC=\"0.5 0.5\" and TOTAL_THREADS=190 order by __step asc')\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595389982038",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}